{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNX7PPmi+zL3wqExekNyrho"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSKEAgBygki6","executionInfo":{"status":"ok","timestamp":1702534759411,"user_tz":-330,"elapsed":3962,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}},"outputId":"94e68f82-e7d8-4b07-9520-69af27dac166"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ooWSLaaw8IVn","executionInfo":{"status":"ok","timestamp":1702535254219,"user_tz":-330,"elapsed":1287,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}},"outputId":"407a9069-5025-4255-dc62-84d98b3e9c7b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Invalid requirement: 'target=/content'\n","Hint: It looks like a path. File 'target=/content' does not exist.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","from ultralytics import YOLO"],"metadata":{"id":"hVgc4P5tggFC","executionInfo":{"status":"ok","timestamp":1702534776935,"user_tz":-330,"elapsed":538,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Load your custom trained model\n","  # Make sure to replace with the actual path to your custom model YAML file\n","model = YOLO()\n","model = model.load(\"/content/runs/detect/train/weights/best.pt\")  # Replace with the path to your trained model weights file\n","\n","\n","# Load a new dataset for inference\n","new_data_path = \"/content/drive/My Drive/Augmented_images\"\n","# new_dataset = model.load_dataset(new_data_path)\n","\n","# Perform inference on the new dataset\n","model.predict(\"/content/drive/My Drive/Augmented_images\", save=True, conf=0.5)  # Replace with the path where you want to save the detection results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQRuil-CgzPZ","executionInfo":{"status":"ok","timestamp":1702535031603,"user_tz":-330,"elapsed":713,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}},"outputId":"b39ebbf9-7fe3-4f1d-ccbb-56a08c450c49"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Transferred 319/355 items from pretrained weights\n","\n","image 1/1 /content/drive/My Drive/Augmented_images/IMG_4971_0_8461.jpeg: 640x640 (no detections), 8.7ms\n","Speed: 1.8ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"," orig_img: array([[[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/drive/My Drive/Augmented_images/IMG_4971_0_8461.jpeg'\n"," probs: None\n"," save_dir: 'runs/detect/predict6'\n"," speed: {'preprocess': 1.8415451049804688, 'inference': 8.677005767822266, 'postprocess': 0.9031295776367188}]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"8viVg7vVyf_X","executionInfo":{"status":"ok","timestamp":1702533215406,"user_tz":-330,"elapsed":396,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["!scp -r /content/runs '/content/drive/My Drive/CustomObjDet/data'"],"metadata":{"id":"H6drUe9W0kmU","executionInfo":{"status":"ok","timestamp":1702533217780,"user_tz":-330,"elapsed":486,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt conf=0.25 source='/content/drive/My Drive/Augmented_images'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZbBUYWBmyZ1","executionInfo":{"status":"ok","timestamp":1702532689174,"user_tz":-330,"elapsed":5363,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}},"outputId":"b59091e0-2042-443b-d9f5-17cc43bf39a1"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 423, in entrypoint\n","    model = YOLO(model, task=task)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 94, in __init__\n","    self._load(model, task)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 146, in _load\n","    self.model, self.ckpt = attempt_load_one_weight(weights)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 628, in attempt_load_one_weight\n","    ckpt, weight = torch_safe_load(weight)  # load ckpt\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 567, in torch_safe_load\n","    return torch.load(file, map_location='cpu'), file  # load\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'runs/detect/train/weights/best.pt'\n"]}]},{"cell_type":"code","source":["results = model(\"/content/drive/My Drive/Augmented_images\")"],"metadata":{"id":"n86D62VMx15z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print or process the detection results\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yRZ-PoXg10l","executionInfo":{"status":"ok","timestamp":1702411099709,"user_tz":-330,"elapsed":4,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}},"outputId":"75c5dd7d-3c2e-4ee0-8006-a2e6c4a4babd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n"," orig_img: array([[[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/drive/My Drive/Augmented_images/IMG_4971_0_8461.jpeg'\n"," probs: None\n"," save_dir: None\n"," speed: {'preprocess': 2.8722286224365234, 'inference': 240.01741409301758, 'postprocess': 1.1372566223144531}]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import cv2\n","\n","# Iterate through each result in the list\n","for result in results:\n","    # Access the original image\n","    image = result.orig_img.copy()\n","\n","    # Check if there are any bounding boxes in the result\n","    if result.boxes is not None and len(result.boxes.xyxy[0]) > 0:\n","        # Access the bounding boxes and draw them on the image\n","        boxes = result.boxes.xyxy[0].cpu().numpy()\n","        for box in boxes:\n","            xy = (int(box[0]), int(box[1]))\n","            xy2 = (int(box[2]), int(box[3]))\n","            image = cv2.rectangle(image, xy, xy2, (0, 255, 0), 2)\n","    else:\n","        print(\"No bounding boxes in the result.\")\n","\n","    # Display the image with bounding boxes\n","    cv2.imshow(\"Detection\", image)\n","    cv2.waitKey(0)\n","\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"lLlVW5ZKn1AB","executionInfo":{"status":"error","timestamp":1702411534670,"user_tz":-330,"elapsed":411,"user":{"displayName":"Priyanshu Kumar Singh","userId":"00760245439851319499"}},"outputId":"3edb0cd4-998e-420b-d060-aa9e82fdfdbc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-f6e782e840d3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Check if there are any bounding boxes in the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Access the bounding boxes and draw them on the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"]}]}]}